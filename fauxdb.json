{"samples": {"735969": {"filename": "file_1.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection/56552", "fauxness": "0.66973040144", "sample_id": "735969"}, "430669": {"filename": "file_1.faux", "active": true, "category_guess": "real", "experiment_name": "observation 60680 ", "fauxness": "0.393531820205", "sample_id": "430669"}, "268240": {"filename": "file_1.faux", "active": true, "category_guess": "real", "experiment_name": "verification/94939_", "fauxness": "0.0359243293929", "sample_id": "268240"}, "525752": {"filename": "file_1.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis_318462", "fauxness": "0.560510361026", "sample_id": "525752"}, "998683": {"filename": "file_1.faux", "active": true, "category_guess": "fake", "experiment_name": "measure32514doover", "fauxness": "0.674479697346", "sample_id": "998683"}, "762885": {"filename": "file_1.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise/79675.2", "fauxness": "0.789747637462", "sample_id": "762885"}, "715150": {"filename": "file_1.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "operation/96190retry", "fauxness": "0.461406697742", "sample_id": "715150"}, "353924": {"filename": "file_1.faux", "active": true, "category_guess": "fake", "experiment_name": "trial_92483_retry", "fauxness": "0.882850918581", "sample_id": "353924"}, "486608": {"filename": "file_1.faux", "active": true, "category_guess": "real", "experiment_name": "proof_56770/retry", "fauxness": "0.221811010991", "sample_id": "486608"}, "911377": {"filename": "file_1.faux", "active": true, "category_guess": "real", "experiment_name": "observation 16606/", "fauxness": "0.309563124949", "sample_id": "911377"}, "449491": {"filename": "file_0.faux", "active": true, "category_guess": "fake", "experiment_name": "examination.76377", "fauxness": "0.651592972723", "sample_id": "449491"}, "247440": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise/12633 ", "fauxness": "0.999128539163", "sample_id": "247440"}, "192230": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise 45913_", "fauxness": "0.830521273633", "sample_id": "192230"}, "902064": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt1999", "fauxness": "0.379075420842", "sample_id": "902064"}, "377205": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt99160doover", "fauxness": "0.660843171612", "sample_id": "377205"}, "581536": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation 49758 2", "fauxness": "0.142137979021", "sample_id": "581536"}, "578961": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt/488662", "fauxness": "0.728941459837", "sample_id": "578961"}, "764295": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run35669/", "fauxness": "0.0976164902136", "sample_id": "764295"}, "197648": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test 94999.doover", "fauxness": "0.150159868268", "sample_id": "197648"}, "701294": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study_7142/doover", "fauxness": "0.219955029668", "sample_id": "701294"}, "376926": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure34323", "fauxness": "0.834316206764", "sample_id": "376926"}, "974845": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof39626doover", "fauxness": "0.20180825869", "sample_id": "974845"}, "170157": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dry run1321.", "fauxness": "0.435607298502", "sample_id": "170157"}, "288744": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise44605doover", "fauxness": "0.0951117205175", "sample_id": "288744"}, "504923": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt52094retry", "fauxness": "0.708177344118", "sample_id": "504923"}, "573671": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection1694", "fauxness": "0.743751937892", "sample_id": "573671"}, "875179": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation/294.", "fauxness": "0.0331214657642", "sample_id": "875179"}, "969868": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection.99045 ", "fauxness": "0.441523873217", "sample_id": "969868"}, "122022": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "attempt 49720_", "fauxness": "0.580736493475", "sample_id": "122022"}, "471298": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice43948.retry", "fauxness": "0.39375292373", "sample_id": "471298"}, "725141": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation19750_", "fauxness": "0.70832112134", "sample_id": "725141"}, "967785": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay36409_", "fauxness": "0.75563119054", "sample_id": "967785"}, "743951": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study 20067doover", "fauxness": "0.647271724017", "sample_id": "743951"}, "981730": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis 90885.2", "fauxness": "0.223668155315", "sample_id": "981730"}, "850482": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation_976802", "fauxness": "0.516274163888", "sample_id": "850482"}, "195741": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay/783272", "fauxness": "0.369972224374", "sample_id": "195741"}, "842637": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection.31199doover", "fauxness": "0.684338998226", "sample_id": "842637"}, "427501": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof.82092 ", "fauxness": "0.489942266216", "sample_id": "427501"}, "270883": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study.26884retry", "fauxness": "0.419735385329", "sample_id": "270883"}, "504236": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt.27394retry", "fauxness": "0.277329117024", "sample_id": "504236"}, "747386": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof36136/retry", "fauxness": "0.249898986773", "sample_id": "747386"}, "793437": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run 82972retry", "fauxness": "0.387940541537", "sample_id": "793437"}, "136805": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test.99308/retry", "fauxness": "0.610285849804", "sample_id": "136805"}, "925314": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test46269/2", "fauxness": "0.0926971966501", "sample_id": "925314"}, "919792": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay/65270", "fauxness": "0.859068446884", "sample_id": "919792"}, "599737": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test82844.retry", "fauxness": "0.319294431972", "sample_id": "599737"}, "721383": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation32679_", "fauxness": "0.348046633859", "sample_id": "721383"}, "99776": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination38929_retry", "fauxness": "0.222603381292", "sample_id": "99776"}, "555853": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure74940", "fauxness": "0.736170971227", "sample_id": "555853"}, "478889": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial run_32676/retry", "fauxness": "0.5628394091", "sample_id": "478889"}, "407822": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof/93124", "fauxness": "0.168961220496", "sample_id": "407822"}, "414833": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification88745 doover", "fauxness": "0.936511735891", "sample_id": "414833"}, "489628": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial/92269 2", "fauxness": "0.366546964157", "sample_id": "489628"}, "127889": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run_30881 ", "fauxness": "0.837838093019", "sample_id": "127889"}, "217493": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study/53366/", "fauxness": "0.526506203343", "sample_id": "217493"}, "34950": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run.64743", "fauxness": "0.371485788424", "sample_id": "34950"}, "688399": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection69894 ", "fauxness": "0.0797115775029", "sample_id": "688399"}, "630283": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise 12740/", "fauxness": "0.965127795019", "sample_id": "630283"}, "985847": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt/3960 doover", "fauxness": "0.358136148052", "sample_id": "985847"}, "365184": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection 47666", "fauxness": "0.346277094876", "sample_id": "365184"}, "140696": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation.37491 ", "fauxness": "0.7099212979", "sample_id": "140696"}, "366424": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof3245", "fauxness": "0.561497108438", "sample_id": "366424"}, "584055": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation 78591.retry", "fauxness": "0.260799195277", "sample_id": "584055"}, "499242": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run86008_doover", "fauxness": "0.653860788336", "sample_id": "499242"}, "456433": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation 73656doover", "fauxness": "0.470030371643", "sample_id": "456433"}, "823234": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation_70933", "fauxness": "0.0884917866304", "sample_id": "823234"}, "881656": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run.21765 ", "fauxness": "0.197303279907", "sample_id": "881656"}, "976968": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt71852", "fauxness": "0.736078664784", "sample_id": "976968"}, "329069": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification 64059retry", "fauxness": "0.854649201732", "sample_id": "329069"}, "510977": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice/45/", "fauxness": "0.481535381943", "sample_id": "510977"}, "147762": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection.98190/", "fauxness": "0.145915528073", "sample_id": "147762"}, "656846": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification/66500doover", "fauxness": "0.25300677426", "sample_id": "656846"}, "696031": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test2776", "fauxness": "0.225543894285", "sample_id": "696031"}, "406049": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation 26311_doover", "fauxness": "0.208444913501", "sample_id": "406049"}, "866471": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test 18897.doover", "fauxness": "0.780189186256", "sample_id": "866471"}, "345897": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study.31449 ", "fauxness": "0.506046584435", "sample_id": "345897"}, "617583": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof 90902/2", "fauxness": "0.61678025995", "sample_id": "617583"}, "239942": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice79658 ", "fauxness": "0.220857317937", "sample_id": "239942"}, "266596": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification 20096 doover", "fauxness": "0.444530303205", "sample_id": "266596"}, "921709": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection23662 2", "fauxness": "0.399167219964", "sample_id": "921709"}, "446637": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dry run38615.doover", "fauxness": "0.598578400989", "sample_id": "446637"}, "755079": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study_88405/", "fauxness": "0.944704679433", "sample_id": "755079"}, "611413": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay_37252_doover", "fauxness": "0.113993309845", "sample_id": "611413"}, "74624": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection54750doover", "fauxness": "0.335339466815", "sample_id": "74624"}, "795581": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation48722", "fauxness": "0.628662734791", "sample_id": "795581"}, "879769": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection/47750_retry", "fauxness": "0.540997318784", "sample_id": "879769"}, "448769": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test 51394_", "fauxness": "0.47410479841", "sample_id": "448769"}, "696896": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run11765/doover", "fauxness": "0.9157858441", "sample_id": "696896"}, "182697": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification_95208 ", "fauxness": "0.159284597251", "sample_id": "182697"}, "606759": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run/35704_retry", "fauxness": "0.275337711502", "sample_id": "606759"}, "701216": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof_71428 ", "fauxness": "0.189895625986", "sample_id": "701216"}, "101295": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial 62934", "fauxness": "0.123797656462", "sample_id": "101295"}, "767737": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise_56852 ", "fauxness": "0.0296048486225", "sample_id": "767737"}, "443553": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation51646 doover", "fauxness": "0.368142949452", "sample_id": "443553"}, "100485": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation19329_doover", "fauxness": "0.845141873733", "sample_id": "100485"}, "689949": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis44802doover", "fauxness": "0.594681710829", "sample_id": "689949"}, "74210": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run_67628", "fauxness": "0.181928345826", "sample_id": "74210"}, "149719": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice56066 2", "fauxness": "0.957643468094", "sample_id": "149719"}, "505197": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis/98480retry", "fauxness": "0.562017536386", "sample_id": "505197"}, "591958": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run/300252", "fauxness": "0.901779719844", "sample_id": "591958"}, "927556": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise.15947", "fauxness": "0.387289956868", "sample_id": "927556"}, "334617": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice7472_", "fauxness": "0.730748312429", "sample_id": "334617"}, "559723": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation/90932 ", "fauxness": "0.621036338524", "sample_id": "559723"}, "41067": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test72502/retry", "fauxness": "0.628120989922", "sample_id": "41067"}, "722280": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay_93824", "fauxness": "0.100401731722", "sample_id": "722280"}, "662622": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination.36155/retry", "fauxness": "0.358848220395", "sample_id": "662622"}, "280850": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt/87066/doover", "fauxness": "0.627690657382", "sample_id": "280850"}, "267984": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice11274", "fauxness": "0.977285422816", "sample_id": "267984"}, "620669": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof/51230.", "fauxness": "0.974476381536", "sample_id": "620669"}, "270549": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run/62783", "fauxness": "0.828925177574", "sample_id": "270549"}, "887228": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study 80260", "fauxness": "0.600731106156", "sample_id": "887228"}, "273314": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis 72116.", "fauxness": "0.723483808069", "sample_id": "273314"}, "135585": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test968852", "fauxness": "0.457274075186", "sample_id": "135585"}, "545961": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection 75701/doover", "fauxness": "0.824928031009", "sample_id": "545961"}, "884974": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial/76113", "fauxness": "0.117141055118", "sample_id": "884974"}, "626495": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis 69378/2", "fauxness": "0.699724358181", "sample_id": "626495"}, "50294": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial.69209doover", "fauxness": "0.335168695729", "sample_id": "50294"}, "205276": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation/22054doover", "fauxness": "0.453237166666", "sample_id": "205276"}, "491035": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation.79358 2", "fauxness": "0.746969064966", "sample_id": "491035"}, "376464": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt32272/", "fauxness": "0.666971534953", "sample_id": "376464"}, "561841": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection.80354 retry", "fauxness": "0.388545240577", "sample_id": "561841"}, "236285": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation33697_2", "fauxness": "0.391504776004", "sample_id": "236285"}, "911427": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure_6103 2", "fauxness": "0.358662426185", "sample_id": "911427"}, "669930": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination.75546", "fauxness": "0.379616801222", "sample_id": "669930"}, "34332": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study_88394", "fauxness": "0.688903171452", "sample_id": "34332"}, "869270": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt.60988_", "fauxness": "0.114413333998", "sample_id": "869270"}, "285640": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial.65769", "fauxness": "0.730786757725", "sample_id": "285640"}, "635203": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination/88592 2", "fauxness": "0.160106813567", "sample_id": "635203"}, "664196": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation43819/", "fauxness": "0.359770198097", "sample_id": "664196"}, "429489": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test91343", "fauxness": "0.0751531662402", "sample_id": "429489"}, "824423": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation.40445_", "fauxness": "0.884613948136", "sample_id": "824423"}, "228088": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation42762/doover", "fauxness": "0.105227245353", "sample_id": "228088"}, "441651": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof61558 ", "fauxness": "0.862434668186", "sample_id": "441651"}, "928330": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection3101", "fauxness": "0.0804012437966", "sample_id": "928330"}, "226630": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation.46399", "fauxness": "0.310000986222", "sample_id": "226630"}, "927830": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run_55255", "fauxness": "0.114315697088", "sample_id": "927830"}, "488887": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test41800.", "fauxness": "0.487750989787", "sample_id": "488887"}, "286830": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study39254", "fauxness": "0.448598533871", "sample_id": "286830"}, "799127": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification7525_doover", "fauxness": "0.0326562738159", "sample_id": "799127"}, "87223": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis 21550_", "fauxness": "0.56086653376", "sample_id": "87223"}, "292712": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation_86905_2", "fauxness": "0.181640825951", "sample_id": "292712"}, "219550": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "operation72705retry", "fauxness": "0.408243190875", "sample_id": "219550"}, "924542": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise13895/", "fauxness": "0.460130277638", "sample_id": "924542"}, "613516": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run58394 ", "fauxness": "0.90340596403", "sample_id": "613516"}, "839350": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice60998.", "fauxness": "0.355384623627", "sample_id": "839350"}, "889150": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice_9438doover", "fauxness": "0.183593867517", "sample_id": "889150"}, "575778": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof41797", "fauxness": "0.884364653187", "sample_id": "575778"}, "749910": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay66158", "fauxness": "0.387382919112", "sample_id": "749910"}, "391769": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation29074retry", "fauxness": "0.187097773627", "sample_id": "391769"}, "444736": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation47018 doover", "fauxness": "0.989047623974", "sample_id": "444736"}, "725309": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination56149", "fauxness": "0.514903792742", "sample_id": "725309"}, "161761": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial 42134_2", "fauxness": "0.465006761844", "sample_id": "161761"}, "667145": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay.8894", "fauxness": "0.209665377884", "sample_id": "667145"}, "753682": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis15444 2", "fauxness": "0.568505103159", "sample_id": "753682"}, "408070": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation43502_", "fauxness": "0.94260751455", "sample_id": "408070"}, "466614": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation44118/", "fauxness": "0.989220805199", "sample_id": "466614"}, "950608": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study33237 ", "fauxness": "0.692552623606", "sample_id": "950608"}, "528199": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof1770", "fauxness": "0.622269434664", "sample_id": "528199"}, "380985": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis/15175", "fauxness": "0.160990378336", "sample_id": "380985"}, "548581": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification12584retry", "fauxness": "0.0680506021095", "sample_id": "548581"}, "698171": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial_51891.", "fauxness": "0.7717226939", "sample_id": "698171"}, "970434": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof22294 2", "fauxness": "0.594226931021", "sample_id": "970434"}, "561230": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation/15212 2", "fauxness": "0.742204045113", "sample_id": "561230"}, "173819": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice 21446 ", "fauxness": "0.120619889902", "sample_id": "173819"}, "41837": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation70223/2", "fauxness": "0.493601179937", "sample_id": "41837"}, "174422": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination 1278/", "fauxness": "0.414656333482", "sample_id": "174422"}, "65729": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation_41259/", "fauxness": "0.552703857329", "sample_id": "65729"}, "138325": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study96265.", "fauxness": "0.881252661929", "sample_id": "138325"}, "526935": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run/40058doover", "fauxness": "0.734009094894", "sample_id": "526935"}, "66430": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination/53761doover", "fauxness": "0.828304426186", "sample_id": "66430"}, "238700": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial5072_retry", "fauxness": "0.956303352258", "sample_id": "238700"}, "376953": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay_96834retry", "fauxness": "0.349339181", "sample_id": "376953"}, "413066": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study/9658", "fauxness": "0.0658820809456", "sample_id": "413066"}, "618681": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run 96102.", "fauxness": "0.160006056554", "sample_id": "618681"}, "537845": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice96736 ", "fauxness": "0.391084950401", "sample_id": "537845"}, "569911": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof 70525 ", "fauxness": "0.848743079836", "sample_id": "569911"}, "477320": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation30949doover", "fauxness": "0.109692534103", "sample_id": "477320"}, "570968": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run44277doover", "fauxness": "0.70642727479", "sample_id": "570968"}, "850741": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis15080retry", "fauxness": "0.738234982455", "sample_id": "850741"}, "381138": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial28729_retry", "fauxness": "0.451936406124", "sample_id": "381138"}, "607983": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation_433202", "fauxness": "0.662864141198", "sample_id": "607983"}, "524592": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run.25869.doover", "fauxness": "0.702047449363", "sample_id": "524592"}, "786768": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run29037_", "fauxness": "0.201983594786", "sample_id": "786768"}, "672206": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation.88888", "fauxness": "0.612083960126", "sample_id": "672206"}, "235430": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation970412", "fauxness": "0.248584348925", "sample_id": "235430"}, "340971": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice75968", "fauxness": "0.805553532487", "sample_id": "340971"}, "183714": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis.28001 2", "fauxness": "0.0299467262643", "sample_id": "183714"}, "862836": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation 231022", "fauxness": "0.959631910278", "sample_id": "862836"}, "659844": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise 31048 retry", "fauxness": "0.501297701824", "sample_id": "659844"}, "853735": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test 16330 ", "fauxness": "0.342985568567", "sample_id": "853735"}, "43460": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt60557", "fauxness": "0.688382998996", "sample_id": "43460"}, "967560": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run61345 doover", "fauxness": "0.311314321862", "sample_id": "967560"}, "763620": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof_22374", "fauxness": "0.222308153711", "sample_id": "763620"}, "428738": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial.25625 retry", "fauxness": "0.783085866179", "sample_id": "428738"}, "504996": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice9133retry", "fauxness": "0.141267912311", "sample_id": "504996"}, "599599": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection59253_2", "fauxness": "0.843598183676", "sample_id": "599599"}, "415353": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise_78074retry", "fauxness": "0.343258430332", "sample_id": "415353"}, "65041": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure 98674", "fauxness": "0.170914560785", "sample_id": "65041"}, "196650": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study_693442", "fauxness": "0.781012478446", "sample_id": "196650"}, "60464": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation_83796/doover", "fauxness": "0.311286781344", "sample_id": "60464"}, "279402": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification.88917_", "fauxness": "0.425111650826", "sample_id": "279402"}, "575239": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination31002.", "fauxness": "0.296017503251", "sample_id": "575239"}, "247873": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification_8312/", "fauxness": "0.0860620738416", "sample_id": "247873"}, "858040": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run/45849.retry", "fauxness": "0.945061770224", "sample_id": "858040"}, "529060": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test 34142", "fauxness": "0.939786332543", "sample_id": "529060"}, "994903": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise.79442.", "fauxness": "0.33389063367", "sample_id": "994903"}, "263667": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection/8879", "fauxness": "0.396191486824", "sample_id": "263667"}, "335885": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise.9526 ", "fauxness": "0.605430354476", "sample_id": "335885"}, "918057": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis.46613.retry", "fauxness": "0.0107331963659", "sample_id": "918057"}, "502785": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure54425", "fauxness": "0.767716283124", "sample_id": "502785"}, "241103": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt23643", "fauxness": "0.935601977729", "sample_id": "241103"}, "636412": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis730382", "fauxness": "0.830453067008", "sample_id": "636412"}, "23999": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection.96511", "fauxness": "0.000783856685141", "sample_id": "23999"}, "512608": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run 29953", "fauxness": "0.989151434353", "sample_id": "512608"}, "918785": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis_69898", "fauxness": "0.780226998915", "sample_id": "918785"}, "462148": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation/45189.retry", "fauxness": "0.367154539228", "sample_id": "462148"}, "328314": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt72811", "fauxness": "0.0805826463529", "sample_id": "328314"}, "412449": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run 62006.doover", "fauxness": "0.854651864585", "sample_id": "412449"}, "366833": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise.97708", "fauxness": "0.730442885613", "sample_id": "366833"}, "31746": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study90326", "fauxness": "0.971334248472", "sample_id": "31746"}, "545071": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection/59165_2", "fauxness": "0.350391404315", "sample_id": "545071"}, "379631": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test50952", "fauxness": "0.69520067589", "sample_id": "379631"}, "-235800": {"filename": "file_7.faux", "active": false, "category_guess": "fake", "experiment_name": "dry run49892.", "fauxness": "0.640073507135", "sample_id": "-235800"}, "268652": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation/3302 doover", "fauxness": "0.725320419725", "sample_id": "268652"}, "207686": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure50641doover", "fauxness": "0.491793696651", "sample_id": "207686"}, "574292": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection 56033.", "fauxness": "0.93861791891", "sample_id": "574292"}, "519059": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection62876.2", "fauxness": "0.115315439089", "sample_id": "519059"}, "946251": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice50557", "fauxness": "0.469535202953", "sample_id": "946251"}, "148283": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run 39651 2", "fauxness": "0.682967095668", "sample_id": "148283"}, "481266": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection/56737retry", "fauxness": "0.974534772784", "sample_id": "481266"}, "484947": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure9602_doover", "fauxness": "0.871378805277", "sample_id": "484947"}, "194817": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection52937_", "fauxness": "0.552572061582", "sample_id": "194817"}, "155000": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice6406 2", "fauxness": "0.868727458275", "sample_id": "155000"}, "743627": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation/94847/", "fauxness": "0.0419540140317", "sample_id": "743627"}, "277150": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis 27672/doover", "fauxness": "0.513398108523", "sample_id": "277150"}, "837730": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study87785 retry", "fauxness": "0.778275839437", "sample_id": "837730"}, "875840": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis 62974 doover", "fauxness": "0.0821180469324", "sample_id": "875840"}, "562847": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation.38762/2", "fauxness": "0.721547948983", "sample_id": "562847"}, "518078": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt53172doover", "fauxness": "0.139340547989", "sample_id": "518078"}, "524527": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test_6944", "fauxness": "0.515806053999", "sample_id": "524527"}, "176593": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation/3764.", "fauxness": "0.267367635197", "sample_id": "176593"}, "903281": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure/58044", "fauxness": "0.264613935761", "sample_id": "903281"}, "939238": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run17442", "fauxness": "0.858650570542", "sample_id": "939238"}, "870252": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial53797", "fauxness": "0.186710450797", "sample_id": "870252"}, "112669": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test4423", "fauxness": "0.743766265052", "sample_id": "112669"}, "120018": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice_21803 ", "fauxness": "0.161204922166", "sample_id": "120018"}, "3201": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation.28643", "fauxness": "0.359126434244", "sample_id": "3201"}, "134129": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay 86990_doover", "fauxness": "0.542147734784", "sample_id": "134129"}, "28645": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof 5970retry", "fauxness": "0.914012257143", "sample_id": "28645"}, "485453": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run 76076_doover", "fauxness": "0.702364897332", "sample_id": "485453"}, "480460": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise29624_2", "fauxness": "0.52693390396", "sample_id": "480460"}, "530603": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof26836 retry", "fauxness": "0.25527041916", "sample_id": "530603"}, "300238": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run_2655retry", "fauxness": "0.11794485638", "sample_id": "300238"}, "407363": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure.12017retry", "fauxness": "0.438595075839", "sample_id": "407363"}, "115393": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt26645", "fauxness": "0.260903140768", "sample_id": "115393"}, "394056": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay/36376_", "fauxness": "0.222514363769", "sample_id": "394056"}, "32917": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "operation91500.", "fauxness": "0.443773851364", "sample_id": "32917"}, "520601": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation/20266/2", "fauxness": "0.875006349898", "sample_id": "520601"}, "811703": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run88400/", "fauxness": "0.0621093769529", "sample_id": "811703"}, "639415": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof/99622/retry", "fauxness": "0.432073157134", "sample_id": "639415"}, "963287": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice17646", "fauxness": "0.089529164243", "sample_id": "963287"}, "506518": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation_78394/doover", "fauxness": "0.897949753432", "sample_id": "506518"}, "496024": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure_43462", "fauxness": "0.892646742711", "sample_id": "496024"}, "561975": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof430222", "fauxness": "0.58969245573", "sample_id": "561975"}, "748788": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice433792", "fauxness": "0.324733844734", "sample_id": "748788"}, "187150": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation94280 doover", "fauxness": "0.970481527044", "sample_id": "187150"}, "492226": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run23939/", "fauxness": "0.362533625683", "sample_id": "492226"}, "5845": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification_42794", "fauxness": "0.083921892427", "sample_id": "5845"}, "226522": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay_15268 doover", "fauxness": "0.359377382468", "sample_id": "226522"}, "859072": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation28625 ", "fauxness": "0.35077919468", "sample_id": "859072"}, "863622": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise 13493 ", "fauxness": "0.169809071166", "sample_id": "863622"}, "478010": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination_65813_", "fauxness": "0.793716382506", "sample_id": "478010"}, "219558": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial83784doover", "fauxness": "0.288951232711", "sample_id": "219558"}, "907046": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis_9279/retry", "fauxness": "0.485872120249", "sample_id": "907046"}, "154780": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run47955.doover", "fauxness": "0.25480540497", "sample_id": "154780"}, "562145": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification345.", "fauxness": "0.207180177655", "sample_id": "562145"}, "277048": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure/94845/", "fauxness": "0.732022272508", "sample_id": "277048"}, "617617": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice.44078 ", "fauxness": "0.400358984841", "sample_id": "617617"}, "128421": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study52456/", "fauxness": "0.134917116662", "sample_id": "128421"}, "137284": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise.87226", "fauxness": "0.436855384659", "sample_id": "137284"}, "927006": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run/43186.", "fauxness": "0.679481922712", "sample_id": "927006"}, "729407": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure_72373.", "fauxness": "0.915876663123", "sample_id": "729407"}, "722281": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise23807.2", "fauxness": "0.89823303391", "sample_id": "722281"}, "29690": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study_50997retry", "fauxness": "0.171422648808", "sample_id": "29690"}, "92352": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure16469", "fauxness": "0.365506124876", "sample_id": "92352"}, "59875": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run.17667", "fauxness": "0.909642107647", "sample_id": "59875"}, "104517": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification_23877", "fauxness": "0.454174271587", "sample_id": "104517"}, "183335": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise75576.retry", "fauxness": "0.996400711148", "sample_id": "183335"}, "519091": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof55692", "fauxness": "0.81960247662", "sample_id": "519091"}, "717339": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt44096", "fauxness": "0.0664090387876", "sample_id": "717339"}, "478287": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run.13096.doover", "fauxness": "0.345809288562", "sample_id": "478287"}, "75866": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice35842retry", "fauxness": "0.766252725974", "sample_id": "75866"}, "472168": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure.4022.", "fauxness": "0.698423649326", "sample_id": "472168"}, "418766": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation31268", "fauxness": "0.237895378019", "sample_id": "418766"}, "494950": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis.41500doover", "fauxness": "0.983085502044", "sample_id": "494950"}, "212858": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination34709/", "fauxness": "0.191258774945", "sample_id": "212858"}, "629727": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run43556_2", "fauxness": "0.723364751028", "sample_id": "629727"}, "381967": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation91168_doover", "fauxness": "0.405818791072", "sample_id": "381967"}, "978584": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay 17126", "fauxness": "0.210954709467", "sample_id": "978584"}, "320350": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation34753/retry", "fauxness": "0.991144613058", "sample_id": "320350"}, "727858": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice/303572", "fauxness": "0.43373701774", "sample_id": "727858"}, "583815": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run_88351.", "fauxness": "0.975440597154", "sample_id": "583815"}, "563124": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice85130_", "fauxness": "0.203954312293", "sample_id": "563124"}, "150818": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure56726_", "fauxness": "0.576286782546", "sample_id": "150818"}, "45344": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay4055doover", "fauxness": "0.264235674122", "sample_id": "45344"}, "523174": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation68787/doover", "fauxness": "0.98301371179", "sample_id": "523174"}, "190651": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation/16764retry", "fauxness": "0.934827991355", "sample_id": "190651"}, "582629": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation95850.doover", "fauxness": "0.626431746183", "sample_id": "582629"}, "773764": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise14241.doover", "fauxness": "0.87807993655", "sample_id": "773764"}, "881693": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay11183_", "fauxness": "0.844065305249", "sample_id": "881693"}, "931589": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination53181.", "fauxness": "0.177688744063", "sample_id": "931589"}, "392056": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial20181", "fauxness": "0.708044600042", "sample_id": "392056"}, "31657": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis/18395 ", "fauxness": "0.464411723224", "sample_id": "31657"}, "976872": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice/14964/", "fauxness": "0.091456731701", "sample_id": "976872"}, "250074": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study/33949", "fauxness": "0.285484765849", "sample_id": "250074"}, "470058": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination 92979", "fauxness": "0.533254195744", "sample_id": "470058"}, "763924": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay/81375", "fauxness": "0.790525273698", "sample_id": "763924"}, "196865": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation/7186", "fauxness": "0.660526611062", "sample_id": "196865"}, "561286": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis/751472", "fauxness": "0.835610693255", "sample_id": "561286"}, "228261": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection91155", "fauxness": "0.382663896364", "sample_id": "228261"}, "435197": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study 24658 doover", "fauxness": "0.974210179178", "sample_id": "435197"}, "700089": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice2182_", "fauxness": "0.702574321997", "sample_id": "700089"}, "759086": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise15869", "fauxness": "0.48361372425", "sample_id": "759086"}, "590101": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt/25976/retry", "fauxness": "0.223537215754", "sample_id": "590101"}, "718810": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise_84632_retry", "fauxness": "0.696815630805", "sample_id": "718810"}, "976898": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run/69593_", "fauxness": "0.202535487678", "sample_id": "976898"}, "401519": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation35413retry", "fauxness": "0.17047696525", "sample_id": "401519"}, "80052": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation.98586 doover", "fauxness": "0.819993656467", "sample_id": "80052"}, "799223": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof/61936", "fauxness": "0.193107248693", "sample_id": "799223"}, "386186": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis75301/", "fauxness": "0.886478188126", "sample_id": "386186"}, "538290": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study78790/", "fauxness": "0.41116321474", "sample_id": "538290"}, "915504": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study 37912_doover", "fauxness": "0.361003276647", "sample_id": "915504"}, "388809": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof/63794.2", "fauxness": "0.571135843838", "sample_id": "388809"}, "474831": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study82155", "fauxness": "0.7026129349", "sample_id": "474831"}, "938781": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt 2812 retry", "fauxness": "0.0304582434182", "sample_id": "938781"}, "295346": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dry run/26422/retry", "fauxness": "0.453522658011", "sample_id": "295346"}, "260620": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test/60151", "fauxness": "0.45379629108", "sample_id": "260620"}, "680154": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure_38024", "fauxness": "0.407203218497", "sample_id": "680154"}, "877746": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof/388702", "fauxness": "0.77612168462", "sample_id": "877746"}, "457484": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run37741 2", "fauxness": "0.311591439218", "sample_id": "457484"}, "169671": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study.16277", "fauxness": "0.184268516629", "sample_id": "169671"}, "199727": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis24702.2", "fauxness": "0.579351953501", "sample_id": "199727"}, "958313": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice 44140/doover", "fauxness": "0.815316797706", "sample_id": "958313"}, "774307": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial83369/", "fauxness": "0.380396617284", "sample_id": "774307"}, "385433": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification_25683", "fauxness": "0.609889880127", "sample_id": "385433"}, "888394": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run70993", "fauxness": "0.913114030057", "sample_id": "888394"}, "162036": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure74669doover", "fauxness": "0.762295636251", "sample_id": "162036"}, "211494": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof10063retry", "fauxness": "0.445484534071", "sample_id": "211494"}, "506584": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof 45907doover", "fauxness": "0.330021750951", "sample_id": "506584"}, "153904": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice79335 doover", "fauxness": "0.437684373402", "sample_id": "153904"}, "880272": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run/25728_", "fauxness": "0.620272711591", "sample_id": "880272"}, "41430": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial52195.", "fauxness": "0.976566895889", "sample_id": "41430"}, "239592": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof98564 2", "fauxness": "0.96770864427", "sample_id": "239592"}, "971466": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure.22893", "fauxness": "0.479956969463", "sample_id": "971466"}, "418427": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial37749_2", "fauxness": "0.360996840997", "sample_id": "418427"}, "51008": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt 48187 retry", "fauxness": "0.300603644847", "sample_id": "51008"}, "474390": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test71278", "fauxness": "0.343670577787", "sample_id": "474390"}, "726908": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run_95175_2", "fauxness": "0.184771177773", "sample_id": "726908"}, "496208": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay/686", "fauxness": "0.55355270299", "sample_id": "496208"}, "389234": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise 56946.", "fauxness": "0.914506294826", "sample_id": "389234"}, "233846": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay82725.retry", "fauxness": "0.467839173266", "sample_id": "233846"}, "808745": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test_30900", "fauxness": "0.76351991014", "sample_id": "808745"}, "445778": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial42511 ", "fauxness": "0.542215094015", "sample_id": "445778"}, "53182": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination26261/2", "fauxness": "0.669515516461", "sample_id": "53182"}, "644393": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run619902", "fauxness": "0.362335935301", "sample_id": "644393"}, "398404": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice/767772", "fauxness": "0.868193754807", "sample_id": "398404"}, "871419": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof 47379", "fauxness": "0.366041299305", "sample_id": "871419"}, "616871": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice/893682", "fauxness": "0.81557619635", "sample_id": "616871"}, "471275": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination/98909doover", "fauxness": "0.767657786928", "sample_id": "471275"}, "209137": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay.5767 ", "fauxness": "0.95488865824", "sample_id": "209137"}, "558191": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise 88600_", "fauxness": "0.197354388174", "sample_id": "558191"}, "979717": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination39617/2", "fauxness": "0.375377656398", "sample_id": "979717"}, "906058": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis.72584/", "fauxness": "0.866278038418", "sample_id": "906058"}, "300673": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof90481doover", "fauxness": "0.582977091861", "sample_id": "300673"}, "324314": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice/249.doover", "fauxness": "0.853867067596", "sample_id": "324314"}, "767045": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure.45650_2", "fauxness": "0.228680221717", "sample_id": "767045"}, "899697": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt18404/", "fauxness": "0.990114611648", "sample_id": "899697"}, "712640": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run17870_", "fauxness": "0.767041771704", "sample_id": "712640"}, "191429": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof75550.retry", "fauxness": "0.830258421402", "sample_id": "191429"}, "970443": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation_75412/2", "fauxness": "0.981987142566", "sample_id": "970443"}, "565696": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run29488/", "fauxness": "0.0825468572349", "sample_id": "565696"}, "981955": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation 26639 ", "fauxness": "0.265931243784", "sample_id": "981955"}, "889190": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof/19916doover", "fauxness": "0.601036100356", "sample_id": "889190"}, "42408": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation3667", "fauxness": "0.00733770211026", "sample_id": "42408"}, "672540": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay.53030.doover", "fauxness": "0.519241569302", "sample_id": "672540"}, "137560": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection/49548.doover", "fauxness": "0.929137677152", "sample_id": "137560"}, "733936": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure_50317_retry", "fauxness": "0.611790580379", "sample_id": "733936"}, "702181": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection.64684.", "fauxness": "0.825616613839", "sample_id": "702181"}, "734781": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run2446/", "fauxness": "0.84757484315", "sample_id": "734781"}, "837456": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination23435doover", "fauxness": "0.395335166372", "sample_id": "837456"}, "620899": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification16556.", "fauxness": "0.747184488557", "sample_id": "620899"}, "98748": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise/71538", "fauxness": "0.0985351125831", "sample_id": "98748"}, "68917": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination_20285", "fauxness": "0.80843785449", "sample_id": "68917"}, "632880": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise81377doover", "fauxness": "0.685581496785", "sample_id": "632880"}, "692167": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study 47058 2", "fauxness": "0.204968160282", "sample_id": "692167"}, "78121": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run57087_", "fauxness": "0.659450119336", "sample_id": "78121"}, "813122": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial51465", "fauxness": "0.887872114465", "sample_id": "813122"}, "30415": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure49152", "fauxness": "0.258952089907", "sample_id": "30415"}, "925564": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure99184 retry", "fauxness": "0.670458178677", "sample_id": "925564"}, "759234": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection/77648 doover", "fauxness": "0.768697136723", "sample_id": "759234"}, "759223": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination52276.", "fauxness": "0.9136666909", "sample_id": "759223"}, "715229": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation44513/2", "fauxness": "0.31353475765", "sample_id": "715229"}, "867597": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination 41402", "fauxness": "0.286413658908", "sample_id": "867597"}, "915314": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test_15771/", "fauxness": "0.564430738101", "sample_id": "915314"}, "864950": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study79141retry", "fauxness": "0.195749928009", "sample_id": "864950"}, "48241": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt32272 2", "fauxness": "0.674681296146", "sample_id": "48241"}, "833864": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination70450_", "fauxness": "0.191531005449", "sample_id": "833864"}, "535789": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation/85528_retry", "fauxness": "0.444799507181", "sample_id": "535789"}, "863463": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study/46778retry", "fauxness": "0.042429572549", "sample_id": "863463"}, "783931": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise17189", "fauxness": "0.600485621447", "sample_id": "783931"}, "57328": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof_75425_doover", "fauxness": "0.136061121422", "sample_id": "57328"}, "826820": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination99132retry", "fauxness": "0.419656930882", "sample_id": "826820"}, "345482": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt.91020.retry", "fauxness": "0.135534724871", "sample_id": "345482"}, "947304": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation.15255.2", "fauxness": "0.945651017743", "sample_id": "947304"}, "640797": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt67854 doover", "fauxness": "0.606036936846", "sample_id": "640797"}, "436427": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation42184/", "fauxness": "0.336254474441", "sample_id": "436427"}, "985638": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial/53385retry", "fauxness": "0.544083969593", "sample_id": "985638"}, "99058": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination66877.", "fauxness": "0.0401795534871", "sample_id": "99058"}, "473104": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay.20970.doover", "fauxness": "0.482840770329", "sample_id": "473104"}, "181257": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay 98968_", "fauxness": "0.639031533602", "sample_id": "181257"}, "756764": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice5852", "fauxness": "0.785764289778", "sample_id": "756764"}, "947538": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis.95050", "fauxness": "0.305196123315", "sample_id": "947538"}, "18113": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification81224.2", "fauxness": "0.14634783748", "sample_id": "18113"}, "532892": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection/89484", "fauxness": "0.0741544747967", "sample_id": "532892"}, "489165": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run69533retry", "fauxness": "0.982872315046", "sample_id": "489165"}, "243700": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study/35439.doover", "fauxness": "0.147718520041", "sample_id": "243700"}, "966107": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "attempt58115", "fauxness": "0.469922274137", "sample_id": "966107"}, "165200": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection2708_", "fauxness": "0.438511251795", "sample_id": "165200"}, "604168": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination_69909retry", "fauxness": "0.317343380006", "sample_id": "604168"}, "125906": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice_62310", "fauxness": "0.846225840023", "sample_id": "125906"}, "140832": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation20165/", "fauxness": "0.0430298494937", "sample_id": "140832"}, "867885": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection29186/", "fauxness": "0.177548580106", "sample_id": "867885"}, "566201": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study30350/doover", "fauxness": "0.715202793003", "sample_id": "566201"}, "112209": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis.52485", "fauxness": "0.300775662273", "sample_id": "112209"}, "397412": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay11830", "fauxness": "0.506604221046", "sample_id": "397412"}, "497297": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise_48010_", "fauxness": "0.838938974613", "sample_id": "497297"}, "707861": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination_95404_2", "fauxness": "0.273161560153", "sample_id": "707861"}, "853643": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "operation55659 2", "fauxness": "0.545546654422", "sample_id": "853643"}, "18102": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof75558 retry", "fauxness": "0.576579342706", "sample_id": "18102"}, "484480": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial423332", "fauxness": "0.135851646802", "sample_id": "484480"}, "807052": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study 36140.doover", "fauxness": "0.448672096274", "sample_id": "807052"}, "562683": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study.73051/", "fauxness": "0.654078325306", "sample_id": "562683"}, "885278": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise/83587retry", "fauxness": "0.297249712134", "sample_id": "885278"}, "345598": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study/45677.retry", "fauxness": "0.994194661832", "sample_id": "345598"}, "991418": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run19888", "fauxness": "0.883565965152", "sample_id": "991418"}, "96291": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study/83257_doover", "fauxness": "0.834077314857", "sample_id": "96291"}, "183217": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay/13007 ", "fauxness": "0.0599151863051", "sample_id": "183217"}, "214687": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise.37029/", "fauxness": "0.358378329366", "sample_id": "214687"}, "151597": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection_83430 ", "fauxness": "0.83371569451", "sample_id": "151597"}, "539709": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay65557", "fauxness": "0.658530457494", "sample_id": "539709"}, "978369": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise31541doover", "fauxness": "0.726872948278", "sample_id": "978369"}, "566702": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run1053", "fauxness": "0.900100442591", "sample_id": "566702"}, "756589": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination53025doover", "fauxness": "0.405924858249", "sample_id": "756589"}, "554523": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation 93332.2", "fauxness": "0.351312002958", "sample_id": "554523"}, "755125": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis/12730/", "fauxness": "0.554286941916", "sample_id": "755125"}, "163700": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination/22158 ", "fauxness": "0.00260126837417", "sample_id": "163700"}, "150553": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation75110.2", "fauxness": "0.600959712707", "sample_id": "150553"}, "135088": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification 43616.", "fauxness": "0.860775556443", "sample_id": "135088"}, "208890": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run 54314.", "fauxness": "0.17590294968", "sample_id": "208890"}, "555002": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay 53353 doover", "fauxness": "0.578413663652", "sample_id": "555002"}, "628478": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run_56632 ", "fauxness": "0.819703739807", "sample_id": "628478"}, "354974": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test_95708_doover", "fauxness": "0.644637420855", "sample_id": "354974"}, "737007": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure 11562/", "fauxness": "0.902460602801", "sample_id": "737007"}, "787913": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run30094_doover", "fauxness": "0.883506504319", "sample_id": "787913"}, "388752": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation_1302_2", "fauxness": "0.951263011487", "sample_id": "388752"}, "652992": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification.79676retry", "fauxness": "0.826229553116", "sample_id": "652992"}, "530324": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination40329/", "fauxness": "0.261001627124", "sample_id": "530324"}, "745928": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure/66136/", "fauxness": "0.180013232419", "sample_id": "745928"}, "216985": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run 89319_doover", "fauxness": "0.846110945966", "sample_id": "216985"}, "429544": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification_231892", "fauxness": "0.735725887035", "sample_id": "429544"}, "512694": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification/47569", "fauxness": "0.804333210775", "sample_id": "512694"}, "861416": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection85883/doover", "fauxness": "0.277503620435", "sample_id": "861416"}, "535350": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial/32373/", "fauxness": "0.887230892934", "sample_id": "535350"}, "423336": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test.7937.doover", "fauxness": "0.881407057718", "sample_id": "423336"}, "162062": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial30203doover", "fauxness": "0.268639740663", "sample_id": "162062"}, "818183": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial5895 doover", "fauxness": "0.871935268591", "sample_id": "818183"}, "321093": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run/59285_", "fauxness": "0.707951548846", "sample_id": "321093"}, "232164": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof 63606", "fauxness": "0.73189662495", "sample_id": "232164"}, "479442": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation51992retry", "fauxness": "0.617690965687", "sample_id": "479442"}, "73626": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection_19275retry", "fauxness": "0.247114492444", "sample_id": "73626"}, "79929": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study52760.2", "fauxness": "0.693123927449", "sample_id": "79929"}, "646388": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test915 ", "fauxness": "0.285918558725", "sample_id": "646388"}, "672160": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof55260.", "fauxness": "0.673181311061", "sample_id": "672160"}, "662475": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test81680doover", "fauxness": "0.0769071507494", "sample_id": "662475"}, "454497": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run_87861_retry", "fauxness": "0.671458264768", "sample_id": "454497"}, "604671": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure70177doover", "fauxness": "0.337433738413", "sample_id": "604671"}, "19977": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation66246.", "fauxness": "0.0868958737771", "sample_id": "19977"}, "416123": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial49109", "fauxness": "0.767229787909", "sample_id": "416123"}, "794408": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination 67369 ", "fauxness": "0.305210976144", "sample_id": "794408"}, "694144": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice 11359doover", "fauxness": "0.514007723609", "sample_id": "694144"}, "657625": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay_90182 2", "fauxness": "0.541034453582", "sample_id": "657625"}, "237074": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis_21616", "fauxness": "0.397696089447", "sample_id": "237074"}, "85169": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination/1430", "fauxness": "0.103827680038", "sample_id": "85169"}, "442462": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination_93037/retry", "fauxness": "0.91895332246", "sample_id": "442462"}, "689062": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice 69093/", "fauxness": "0.757815205664", "sample_id": "689062"}, "505726": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof_58973", "fauxness": "0.900655731134", "sample_id": "505726"}, "93652": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice 54581.", "fauxness": "0.985236921012", "sample_id": "93652"}, "898549": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run.71022/2", "fauxness": "0.0657050016145", "sample_id": "898549"}, "325476": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt36496 ", "fauxness": "0.846040352698", "sample_id": "325476"}, "186194": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run/63312/retry", "fauxness": "0.949469625241", "sample_id": "186194"}, "122368": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test/90983_", "fauxness": "0.326419705389", "sample_id": "122368"}, "940507": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial run42156", "fauxness": "0.525117720345", "sample_id": "940507"}, "562285": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial 24971 retry", "fauxness": "0.808016298235", "sample_id": "562285"}, "64397": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification53492", "fauxness": "0.542010036697", "sample_id": "64397"}, "925881": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial16414.", "fauxness": "0.973307463767", "sample_id": "925881"}, "890175": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise92757_", "fauxness": "0.449107236885", "sample_id": "890175"}, "151572": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure_46577.doover", "fauxness": "0.00271449883833", "sample_id": "151572"}, "83969": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt.30528_retry", "fauxness": "0.866478297885", "sample_id": "83969"}, "636544": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation 15067doover", "fauxness": "0.168471263203", "sample_id": "636544"}, "300507": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation.36008", "fauxness": "0.323218433553", "sample_id": "300507"}, "697934": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt 85417doover", "fauxness": "0.149796994722", "sample_id": "697934"}, "276706": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt_63223retry", "fauxness": "0.157345178187", "sample_id": "276706"}, "862928": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise/56559", "fauxness": "0.506209344541", "sample_id": "862928"}, "884317": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise68855", "fauxness": "0.208669452823", "sample_id": "884317"}, "650320": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof/85926", "fauxness": "0.281112138475", "sample_id": "650320"}, "192013": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure56134.retry", "fauxness": "0.923010400666", "sample_id": "192013"}, "174980": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation262012", "fauxness": "0.355826315018", "sample_id": "174980"}, "181526": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial 63060/", "fauxness": "0.604540761177", "sample_id": "181526"}, "225764": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study 32640", "fauxness": "0.73071935156", "sample_id": "225764"}, "61601": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation72753", "fauxness": "0.156726139524", "sample_id": "61601"}, "1007": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation67855/2", "fauxness": "0.679778493874", "sample_id": "1007"}, "927009": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation_13461", "fauxness": "0.400435907224", "sample_id": "927009"}, "969335": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification45256doover", "fauxness": "0.00149592408737", "sample_id": "969335"}, "134490": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection 43474doover", "fauxness": "0.0938243121277", "sample_id": "134490"}, "528250": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial.40878retry", "fauxness": "0.627880359333", "sample_id": "528250"}, "860285": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study84537doover", "fauxness": "0.0316413048503", "sample_id": "860285"}, "199347": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof_34321", "fauxness": "0.703962211879", "sample_id": "199347"}, "150849": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection.65848", "fauxness": "0.792857166496", "sample_id": "150849"}, "934279": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation59280 ", "fauxness": "0.145362297863", "sample_id": "934279"}, "73618": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt_18858_", "fauxness": "0.336264996959", "sample_id": "73618"}, "905562": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection 72558", "fauxness": "0.0961015577712", "sample_id": "905562"}, "427077": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation.143732", "fauxness": "0.196878533158", "sample_id": "427077"}, "753768": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation51418_", "fauxness": "0.907232152963", "sample_id": "753768"}, "71822": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice/91442", "fauxness": "0.768906816152", "sample_id": "71822"}, "777180": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation_33210doover", "fauxness": "0.672127505686", "sample_id": "777180"}, "324690": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation20494 ", "fauxness": "0.720092593794", "sample_id": "324690"}, "623291": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial28969 ", "fauxness": "0.814504575596", "sample_id": "623291"}, "981672": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study62327.doover", "fauxness": "0.22579713345", "sample_id": "981672"}, "69301": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt.4823doover", "fauxness": "0.151468360283", "sample_id": "69301"}, "353901": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation71720 doover", "fauxness": "0.965644120801", "sample_id": "353901"}, "354137": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test10829", "fauxness": "0.585446758737", "sample_id": "354137"}, "112962": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination 57791.", "fauxness": "0.674421108028", "sample_id": "112962"}, "229650": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection31650 doover", "fauxness": "0.837535222083", "sample_id": "229650"}, "856987": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study67606", "fauxness": "0.944315665098", "sample_id": "856987"}, "481532": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise.41305", "fauxness": "0.467287816454", "sample_id": "481532"}, "378904": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection_70983.retry", "fauxness": "0.461861357658", "sample_id": "378904"}, "800475": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt.12356", "fauxness": "0.815045237923", "sample_id": "800475"}, "12990": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation12933_doover", "fauxness": "0.939917562675", "sample_id": "12990"}, "621709": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification.28322/retry", "fauxness": "0.974446039547", "sample_id": "621709"}, "985500": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study32423/2", "fauxness": "0.436219962184", "sample_id": "985500"}, "149569": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run745602", "fauxness": "0.960858977709", "sample_id": "149569"}, "542508": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification/327332", "fauxness": "0.14433989589", "sample_id": "542508"}, "197475": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification90057/retry", "fauxness": "0.603480078899", "sample_id": "197475"}, "455136": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation/8579.", "fauxness": "0.426286812972", "sample_id": "455136"}, "757390": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof68450", "fauxness": "0.882892200338", "sample_id": "757390"}, "655108": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial2526retry", "fauxness": "0.252067215542", "sample_id": "655108"}, "768206": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay3080.doover", "fauxness": "0.779725463571", "sample_id": "768206"}, "887933": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof17772.doover", "fauxness": "0.413018281432", "sample_id": "887933"}, "949322": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial run/45147/retry", "fauxness": "0.592043034661", "sample_id": "949322"}, "672355": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice 4587", "fauxness": "0.957832949951", "sample_id": "672355"}, "627583": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run10232 ", "fauxness": "0.754932347907", "sample_id": "627583"}, "891188": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study57495/retry", "fauxness": "0.444635591517", "sample_id": "891188"}, "282890": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test/70944retry", "fauxness": "0.337673967019", "sample_id": "282890"}, "733082": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification 87522 ", "fauxness": "0.172106009134", "sample_id": "733082"}, "871935": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification88008/", "fauxness": "0.524557758026", "sample_id": "871935"}, "577335": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation64579/2", "fauxness": "0.293880248256", "sample_id": "577335"}, "476599": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification_61033 2", "fauxness": "0.421936523937", "sample_id": "476599"}, "267712": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay22492", "fauxness": "0.811693998416", "sample_id": "267712"}, "523847": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay97727_", "fauxness": "0.833095252168", "sample_id": "523847"}, "420013": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis/39227doover", "fauxness": "0.628816685188", "sample_id": "420013"}, "104715": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt19918", "fauxness": "0.884895646855", "sample_id": "104715"}, "902039": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification/78752/2", "fauxness": "0.706099248633", "sample_id": "902039"}, "240422": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run4601", "fauxness": "0.642298000535", "sample_id": "240422"}, "654373": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test37505 doover", "fauxness": "0.113389804302", "sample_id": "654373"}, "782220": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation/3787.", "fauxness": "0.868399005563", "sample_id": "782220"}, "660085": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial18562", "fauxness": "0.096694116464", "sample_id": "660085"}, "592060": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis56446retry", "fauxness": "0.46786337251", "sample_id": "592060"}, "609610": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection.78573 ", "fauxness": "0.705321589257", "sample_id": "609610"}, "881072": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay61299", "fauxness": "0.351771988138", "sample_id": "881072"}, "43767": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test64449/", "fauxness": "0.701506773362", "sample_id": "43767"}, "454636": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis.64065 doover", "fauxness": "0.105774034545", "sample_id": "454636"}, "310919": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial43580doover", "fauxness": "0.0690391800018", "sample_id": "310919"}, "74026": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis 4370", "fauxness": "0.123129925933", "sample_id": "74026"}, "269873": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation55350.doover", "fauxness": "0.349427496274", "sample_id": "269873"}, "389882": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation 52194/2", "fauxness": "0.775150954117", "sample_id": "389882"}, "867778": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure.15479 ", "fauxness": "0.241139842707", "sample_id": "867778"}, "562865": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification93809.", "fauxness": "0.992113348639", "sample_id": "562865"}, "550810": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis.43102", "fauxness": "0.759302942136", "sample_id": "550810"}, "490809": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation14046 retry", "fauxness": "0.795078577687", "sample_id": "490809"}, "50138": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise 148502", "fauxness": "0.318500851828", "sample_id": "50138"}, "155350": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation/79207 ", "fauxness": "0.169011095063", "sample_id": "155350"}, "252155": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification_66347 doover", "fauxness": "0.169961262629", "sample_id": "252155"}, "638314": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification12691_doover", "fauxness": "0.391964334848", "sample_id": "638314"}, "328170": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial49284/retry", "fauxness": "0.231856023405", "sample_id": "328170"}, "906504": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study775042", "fauxness": "0.0628898527523", "sample_id": "906504"}, "160214": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise_68761", "fauxness": "0.587590392299", "sample_id": "160214"}, "572488": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial53472.", "fauxness": "0.468016721038", "sample_id": "572488"}, "352467": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis.87306.2", "fauxness": "0.893822451738", "sample_id": "352467"}, "38818": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice612222", "fauxness": "0.829441561194", "sample_id": "38818"}, "625378": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof/38269.", "fauxness": "0.1829137458", "sample_id": "625378"}, "493818": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification/41390retry", "fauxness": "0.130813603631", "sample_id": "493818"}, "653563": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis_58401", "fauxness": "0.594220708006", "sample_id": "653563"}, "390334": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt57297doover", "fauxness": "0.608823228597", "sample_id": "390334"}, "213259": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run/34844 doover", "fauxness": "0.302892839304", "sample_id": "213259"}, "460563": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run30159 2", "fauxness": "0.367545593339", "sample_id": "460563"}, "153260": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice78163.doover", "fauxness": "0.980482312854", "sample_id": "153260"}, "265430": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination17116_", "fauxness": "0.598646399987", "sample_id": "265430"}, "576674": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation_44618_retry", "fauxness": "0.157739332131", "sample_id": "576674"}, "767100": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise/19300", "fauxness": "0.669492934308", "sample_id": "767100"}, "351792": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study69068retry", "fauxness": "0.35976452422", "sample_id": "351792"}, "679487": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection46218.", "fauxness": "0.503948230772", "sample_id": "679487"}, "682118": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection92957retry", "fauxness": "0.286166103307", "sample_id": "682118"}, "483505": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation91444.", "fauxness": "0.7950649546", "sample_id": "483505"}, "394239": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt 61477_", "fauxness": "0.00533477510897", "sample_id": "394239"}, "619622": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure15864.", "fauxness": "0.631903318398", "sample_id": "619622"}, "890882": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial41428", "fauxness": "0.974588923665", "sample_id": "890882"}, "806621": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation88550 ", "fauxness": "0.830506630525", "sample_id": "806621"}, "810575": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial run/47089.", "fauxness": "0.528626361285", "sample_id": "810575"}, "123520": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice/48752doover", "fauxness": "0.0151251334326", "sample_id": "123520"}, "892896": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation466152", "fauxness": "0.0780717999802", "sample_id": "892896"}, "357904": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "attempt 9643/", "fauxness": "0.498876167655", "sample_id": "357904"}, "342471": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure.89675/doover", "fauxness": "0.597750904921", "sample_id": "342471"}, "97760": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "attempt35466 ", "fauxness": "0.420506469813", "sample_id": "97760"}, "114726": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure 50045", "fauxness": "0.557288647684", "sample_id": "114726"}, "919157": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination_58904.doover", "fauxness": "0.511653434316", "sample_id": "919157"}, "130251": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination.73832", "fauxness": "0.161506440494", "sample_id": "130251"}, "178280": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice61697/2", "fauxness": "0.0458485822329", "sample_id": "178280"}, "978933": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial76490 ", "fauxness": "0.965909066614", "sample_id": "978933"}, "471864": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice 88799", "fauxness": "0.503907997211", "sample_id": "471864"}, "954463": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection.25899.doover", "fauxness": "0.519688471019", "sample_id": "954463"}, "269568": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test/25073", "fauxness": "0.0797513699004", "sample_id": "269568"}, "666484": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study86825doover", "fauxness": "0.63281965314", "sample_id": "666484"}, "420877": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test65036_", "fauxness": "0.170396350064", "sample_id": "420877"}, "490938": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "attempt_5898 doover", "fauxness": "0.582828562853", "sample_id": "490938"}, "439916": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination.1696doover", "fauxness": "0.523410729794", "sample_id": "439916"}, "798790": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise269062", "fauxness": "0.281748479315", "sample_id": "798790"}, "287962": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination/12429", "fauxness": "0.677706266514", "sample_id": "287962"}, "938609": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise42763_doover", "fauxness": "0.0283148020102", "sample_id": "938609"}, "565391": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run 45645_retry", "fauxness": "0.689654485194", "sample_id": "565391"}, "258829": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure41051.", "fauxness": "0.646178911034", "sample_id": "258829"}, "272150": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection426.doover", "fauxness": "0.074209238959", "sample_id": "272150"}, "566593": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation14315", "fauxness": "0.799639810843", "sample_id": "566593"}, "4629": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run88737", "fauxness": "0.369770842195", "sample_id": "4629"}, "-254011": {"filename": "file_7.faux", "active": false, "category_guess": "real", "experiment_name": "practice27081retry", "fauxness": "0.378126696067", "sample_id": "-254011"}, "273694": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation_42596.doover", "fauxness": "0.882159964909", "sample_id": "273694"}, "971704": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dry run 74470retry", "fauxness": "0.474793607097", "sample_id": "971704"}, "19002": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study_52009 ", "fauxness": "0.0502472925623", "sample_id": "19002"}, "191519": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study/85419", "fauxness": "0.82907186436", "sample_id": "191519"}, "737151": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation 19153/", "fauxness": "0.642812687678", "sample_id": "737151"}, "261331": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation59636/retry", "fauxness": "0.705021690931", "sample_id": "261331"}, "230338": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection/82461.", "fauxness": "0.726539920827", "sample_id": "230338"}, "81824": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt/94833.", "fauxness": "0.251825094031", "sample_id": "81824"}, "447757": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation.68049doover", "fauxness": "0.704623555532", "sample_id": "447757"}, "363399": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test41015.doover", "fauxness": "0.873299496493", "sample_id": "363399"}, "758699": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial22485_", "fauxness": "0.631224743611", "sample_id": "758699"}, "256957": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise 42240", "fauxness": "0.254322909398", "sample_id": "256957"}, "985225": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof87093/retry", "fauxness": "0.383847911186", "sample_id": "985225"}, "647401": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination/1478.", "fauxness": "0.132273614739", "sample_id": "647401"}, "120339": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation.84885.retry", "fauxness": "0.740377591951", "sample_id": "120339"}, "350642": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection61385doover", "fauxness": "0.688696959726", "sample_id": "350642"}, "499435": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay_31239_", "fauxness": "0.547249813653", "sample_id": "499435"}, "97659": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification.33643_", "fauxness": "0.456103041477", "sample_id": "97659"}, "466014": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study41897retry", "fauxness": "0.0906457130852", "sample_id": "466014"}, "39715": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination99152retry", "fauxness": "0.0147159173855", "sample_id": "39715"}, "624015": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run_99024", "fauxness": "0.852440805569", "sample_id": "624015"}, "574459": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run32429", "fauxness": "0.983867566404", "sample_id": "574459"}, "544181": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection 98352", "fauxness": "0.930743713207", "sample_id": "544181"}, "107522": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay.2711", "fauxness": "0.204123030413", "sample_id": "107522"}, "716369": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run.78506/retry", "fauxness": "0.176190314348", "sample_id": "716369"}, "101712": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial 23633/doover", "fauxness": "0.3878334084", "sample_id": "101712"}, "394374": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection_48140retry", "fauxness": "0.71367764681", "sample_id": "394374"}, "163825": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study55883.", "fauxness": "0.222168206921", "sample_id": "163825"}, "454068": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay_10155retry", "fauxness": "0.462396642465", "sample_id": "454068"}, "996239": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure12781.", "fauxness": "0.678679870031", "sample_id": "996239"}, "948546": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice74208 2", "fauxness": "0.527202638442", "sample_id": "948546"}, "331343": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dry run/97620_", "fauxness": "0.448603300634", "sample_id": "331343"}, "407997": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run91493/2", "fauxness": "0.840054024958", "sample_id": "407997"}, "537079": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection 677702", "fauxness": "0.929492709773", "sample_id": "537079"}, "347426": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test.81041.doover", "fauxness": "0.56944754371", "sample_id": "347426"}, "435944": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test 93646retry", "fauxness": "0.0948973938435", "sample_id": "435944"}, "697296": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test_38280.", "fauxness": "0.226623401313", "sample_id": "697296"}, "732523": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure.162402", "fauxness": "0.0275324716913", "sample_id": "732523"}, "967177": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation.924182", "fauxness": "0.915135668792", "sample_id": "967177"}, "899328": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt74168", "fauxness": "0.170642388193", "sample_id": "899328"}, "324086": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice.38940.", "fauxness": "0.218107146512", "sample_id": "324086"}, "785939": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study46843_", "fauxness": "0.29239426091", "sample_id": "785939"}, "667608": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation13180", "fauxness": "0.773083900666", "sample_id": "667608"}, "255222": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "attempt.42802/", "fauxness": "0.477154054989", "sample_id": "255222"}, "708006": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation58135.", "fauxness": "0.169384327454", "sample_id": "708006"}, "945855": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation132102", "fauxness": "0.690689940972", "sample_id": "945855"}, "131971": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof_16752.2", "fauxness": "0.6019651255", "sample_id": "131971"}, "868695": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test22975doover", "fauxness": "0.035084441164", "sample_id": "868695"}, "23334": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial_1086 retry", "fauxness": "0.631628252143", "sample_id": "23334"}, "748975": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure_95808_2", "fauxness": "0.0924007096068", "sample_id": "748975"}, "997405": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification2152", "fauxness": "0.0257492399464", "sample_id": "997405"}, "701486": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial33928_", "fauxness": "0.987853648277", "sample_id": "701486"}, "84620": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof65727retry", "fauxness": "0.23591340193", "sample_id": "84620"}, "530261": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "attempt/94768.", "fauxness": "0.598637172767", "sample_id": "530261"}, "692998": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification73767/2", "fauxness": "0.543995028105", "sample_id": "692998"}, "887695": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure/42830retry", "fauxness": "0.773645003491", "sample_id": "887695"}, "879604": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run_833952", "fauxness": "0.843897611885", "sample_id": "879604"}, "404609": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial40492", "fauxness": "0.881804137203", "sample_id": "404609"}, "333135": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof/20851 2", "fauxness": "0.202326705255", "sample_id": "333135"}, "942154": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure.95809", "fauxness": "0.383166104743", "sample_id": "942154"}, "850672": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run64307", "fauxness": "0.173214628682", "sample_id": "850672"}, "532233": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation66669 ", "fauxness": "0.564663623504", "sample_id": "532233"}, "524634": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise 73982", "fauxness": "0.759419392562", "sample_id": "524634"}, "460497": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice.44931_2", "fauxness": "0.259424478789", "sample_id": "460497"}, "496915": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification45728.doover", "fauxness": "0.211114288918", "sample_id": "496915"}, "586568": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test/26834/doover", "fauxness": "0.958195612353", "sample_id": "586568"}, "230352": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis_78457retry", "fauxness": "0.471154410883", "sample_id": "230352"}, "960051": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure64614 doover", "fauxness": "0.666613763658", "sample_id": "960051"}, "460149": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification 18077_2", "fauxness": "0.876657673423", "sample_id": "460149"}, "533693": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation/70128.2", "fauxness": "0.697328691651", "sample_id": "533693"}, "315356": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification/67567", "fauxness": "0.332224025447", "sample_id": "315356"}, "550873": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination.29321", "fauxness": "0.229372507473", "sample_id": "550873"}, "756347": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof10726", "fauxness": "0.238208035686", "sample_id": "756347"}, "276246": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise25089", "fauxness": "0.106932000225", "sample_id": "276246"}, "706932": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination.1081.", "fauxness": "0.386751420023", "sample_id": "706932"}, "415056": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice38284/2", "fauxness": "0.458801568422", "sample_id": "415056"}, "889391": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis 96449_retry", "fauxness": "0.799204333325", "sample_id": "889391"}, "325389": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure.24341", "fauxness": "0.209765530215", "sample_id": "325389"}, "600005": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification86833.", "fauxness": "0.531517153362", "sample_id": "600005"}, "309549": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial9700.2", "fauxness": "0.761452709162", "sample_id": "309549"}, "167968": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis 24448 ", "fauxness": "0.848492768773", "sample_id": "167968"}, "618189": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination115552", "fauxness": "0.886319198601", "sample_id": "618189"}, "512418": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay86881", "fauxness": "0.821184873254", "sample_id": "512418"}, "158806": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation4960.", "fauxness": "0.0268165218342", "sample_id": "158806"}, "172065": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise88210/doover", "fauxness": "0.822304655664", "sample_id": "172065"}, "869644": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise60152.", "fauxness": "0.148020367057", "sample_id": "869644"}, "17265": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial/32982retry", "fauxness": "0.69725311938", "sample_id": "17265"}, "397384": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run98253retry", "fauxness": "0.943568224698", "sample_id": "397384"}, "381333": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis39969.", "fauxness": "0.688210674236", "sample_id": "381333"}, "923372": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt88101", "fauxness": "0.951312028253", "sample_id": "923372"}, "719490": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt/36197retry", "fauxness": "0.820073802709", "sample_id": "719490"}, "133622": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure33118.2", "fauxness": "0.486145954106", "sample_id": "133622"}, "325958": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure83315_2", "fauxness": "0.496019224602", "sample_id": "325958"}, "635039": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification86464 doover", "fauxness": "0.60651282355", "sample_id": "635039"}, "72879": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation/6517doover", "fauxness": "0.5510048285", "sample_id": "72879"}, "285574": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice.12968", "fauxness": "0.263575678161", "sample_id": "285574"}, "785002": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run 59208doover", "fauxness": "0.130094621357", "sample_id": "785002"}, "609611": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run9876 ", "fauxness": "0.0875877044108", "sample_id": "609611"}, "141682": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice79657/", "fauxness": "0.230644006797", "sample_id": "141682"}, "221079": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study4936doover", "fauxness": "0.54954370964", "sample_id": "221079"}, "67106": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation60563/doover", "fauxness": "0.115847470785", "sample_id": "67106"}, "675043": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection/91991 retry", "fauxness": "0.385841716959", "sample_id": "675043"}, "534520": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise/697272", "fauxness": "0.987635793961", "sample_id": "534520"}, "153754": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study/601912", "fauxness": "0.181331417262", "sample_id": "153754"}, "809646": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial run.5990", "fauxness": "0.50518218947", "sample_id": "809646"}, "604224": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice94152/retry", "fauxness": "0.117784594498", "sample_id": "604224"}, "325442": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study15066doover", "fauxness": "0.910013990241", "sample_id": "325442"}, "252182": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation_1355_", "fauxness": "0.145726686594", "sample_id": "252182"}, "612091": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run.81128.", "fauxness": "0.0268113150476", "sample_id": "612091"}, "321802": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection.58357doover", "fauxness": "0.167392051216", "sample_id": "321802"}, "525223": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation_50524", "fauxness": "0.201446708306", "sample_id": "525223"}, "713430": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt93386_", "fauxness": "0.894585890593", "sample_id": "713430"}, "669170": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run794292", "fauxness": "0.195335558587", "sample_id": "669170"}, "867583": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run_68265_", "fauxness": "0.934113159619", "sample_id": "867583"}, "743519": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt95385.doover", "fauxness": "0.122677987957", "sample_id": "743519"}, "899859": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay.47332_", "fauxness": "0.966489134307", "sample_id": "899859"}, "326177": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study49486", "fauxness": "0.257168048606", "sample_id": "326177"}, "164268": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run76162retry", "fauxness": "0.106755610956", "sample_id": "164268"}, "792136": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation.64001retry", "fauxness": "0.876385023437", "sample_id": "792136"}, "362132": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification768782", "fauxness": "0.286880984624", "sample_id": "362132"}, "651327": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination 91475", "fauxness": "0.867596180075", "sample_id": "651327"}, "974722": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis89390", "fauxness": "0.505891884625", "sample_id": "974722"}, "922005": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification.5869", "fauxness": "0.422912583843", "sample_id": "922005"}, "787494": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification 9578_2", "fauxness": "0.778376546582", "sample_id": "787494"}, "838153": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise72804 retry", "fauxness": "0.122971805367", "sample_id": "838153"}, "88670": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "practice/11341/doover", "fauxness": "0.756249629482", "sample_id": "88670"}, "263548": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure73815retry", "fauxness": "0.505533283561", "sample_id": "263548"}, "339851": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test31844doover", "fauxness": "0.621141019486", "sample_id": "339851"}, "109850": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run_50949/doover", "fauxness": "0.00707477409665", "sample_id": "109850"}, "712675": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation31962.", "fauxness": "0.0624371058014", "sample_id": "712675"}, "393493": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification/34115 ", "fauxness": "0.319416974572", "sample_id": "393493"}, "769062": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination/55065", "fauxness": "0.726392873595", "sample_id": "769062"}, "472897": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial run/80745retry", "fauxness": "0.524841662932", "sample_id": "472897"}, "767896": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test.5882/", "fauxness": "0.41735026852", "sample_id": "767896"}, "726765": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dry run_22473", "fauxness": "0.526330954027", "sample_id": "726765"}, "876291": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial/36622/", "fauxness": "0.0365357883916", "sample_id": "876291"}, "360268": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "attempt96504.2", "fauxness": "0.434673052496", "sample_id": "360268"}, "750167": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification/94172 retry", "fauxness": "0.134882216532", "sample_id": "750167"}, "792304": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis/65649/", "fauxness": "0.607721994175", "sample_id": "792304"}, "354324": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation/54816 ", "fauxness": "0.101469921561", "sample_id": "354324"}, "639574": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis91781", "fauxness": "0.00682844697919", "sample_id": "639574"}, "997368": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation 453362", "fauxness": "0.317893805299", "sample_id": "997368"}, "792709": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation73000.2", "fauxness": "0.439601095379", "sample_id": "792709"}, "874249": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run/43998 ", "fauxness": "0.0279233355903", "sample_id": "874249"}, "353564": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study18179_", "fauxness": "0.685557672871", "sample_id": "353564"}, "820831": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure 55703", "fauxness": "0.543352633487", "sample_id": "820831"}, "444471": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run.85344 retry", "fauxness": "0.616556109638", "sample_id": "444471"}, "200615": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study64861 ", "fauxness": "0.156501099448", "sample_id": "200615"}, "802553": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study24268", "fauxness": "0.395484528265", "sample_id": "802553"}, "757589": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise48090", "fauxness": "0.123336156435", "sample_id": "757589"}, "646755": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination969802", "fauxness": "0.314861114073", "sample_id": "646755"}, "752544": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection94445", "fauxness": "0.722166656068", "sample_id": "752544"}, "684971": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt223702", "fauxness": "0.0490648075159", "sample_id": "684971"}, "126138": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run/52879/", "fauxness": "0.35580513376", "sample_id": "126138"}, "874710": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation58264 ", "fauxness": "0.375977413196", "sample_id": "874710"}, "163831": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof/42726", "fauxness": "0.0117743006695", "sample_id": "163831"}, "659963": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial27222_", "fauxness": "0.80602487568", "sample_id": "659963"}, "234689": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof 98210", "fauxness": "0.331832139939", "sample_id": "234689"}, "917270": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis_69844/2", "fauxness": "0.301251592608", "sample_id": "917270"}, "524028": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis58677doover", "fauxness": "0.795424422766", "sample_id": "524028"}, "746840": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection_794032", "fauxness": "0.72068522338", "sample_id": "746840"}, "851608": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run/7637", "fauxness": "0.329157218354", "sample_id": "851608"}, "848164": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run46743", "fauxness": "0.753362319294", "sample_id": "848164"}, "143839": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study/2121/retry", "fauxness": "0.264191232076", "sample_id": "143839"}, "200662": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise8527 ", "fauxness": "0.11314782724", "sample_id": "200662"}, "704725": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay 64228/", "fauxness": "0.945168430607", "sample_id": "704725"}, "793011": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis_9831 ", "fauxness": "0.960882491968", "sample_id": "793011"}, "785707": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay 87068 ", "fauxness": "0.123801314046", "sample_id": "785707"}, "485820": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay 48187retry", "fauxness": "0.988683631933", "sample_id": "485820"}, "170815": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure55807 doover", "fauxness": "0.0737787760806", "sample_id": "170815"}, "412469": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis.130542", "fauxness": "0.584206143948", "sample_id": "412469"}, "146019": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study88932/2", "fauxness": "0.0540032341923", "sample_id": "146019"}, "886107": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run96439_", "fauxness": "0.834769809689", "sample_id": "886107"}, "756659": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test11510", "fauxness": "0.564633482594", "sample_id": "756659"}, "632762": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt44922", "fauxness": "0.0713989243607", "sample_id": "632762"}, "877575": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination.30215.", "fauxness": "0.434682892358", "sample_id": "877575"}, "709212": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection19467 ", "fauxness": "0.483066959756", "sample_id": "709212"}, "298970": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise41197", "fauxness": "0.963953269748", "sample_id": "298970"}, "200074": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure 4300_retry", "fauxness": "0.304989030965", "sample_id": "200074"}, "468078": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study31561/doover", "fauxness": "0.43274889667", "sample_id": "468078"}, "375511": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation/75344/2", "fauxness": "0.272766825904", "sample_id": "375511"}, "384838": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise47189", "fauxness": "0.62344619231", "sample_id": "384838"}, "50621": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study.37245", "fauxness": "0.0962446577565", "sample_id": "50621"}, "90387": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection 84076_", "fauxness": "0.937814964007", "sample_id": "90387"}, "248173": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run62307/doover", "fauxness": "0.814133240401", "sample_id": "248173"}, "871669": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination 3917 ", "fauxness": "0.58837570467", "sample_id": "871669"}, "803469": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "operation/34152 ", "fauxness": "0.85975335037", "sample_id": "803469"}, "812456": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis97403.2", "fauxness": "0.284652507981", "sample_id": "812456"}, "227409": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis.27889/", "fauxness": "0.985159366399", "sample_id": "227409"}, "497299": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay 65090", "fauxness": "0.108565873451", "sample_id": "497299"}, "335237": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise52641/", "fauxness": "0.998367488269", "sample_id": "335237"}, "974252": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection78075/retry", "fauxness": "0.747173657976", "sample_id": "974252"}, "33689": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run25173", "fauxness": "0.773054322344", "sample_id": "33689"}, "683409": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt87428", "fauxness": "0.653335832838", "sample_id": "683409"}, "312370": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run 83005", "fauxness": "0.119553076469", "sample_id": "312370"}, "241042": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation10281", "fauxness": "0.777981804285", "sample_id": "241042"}, "322021": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial_6552retry", "fauxness": "0.629252684832", "sample_id": "322021"}, "366062": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial/86404/", "fauxness": "0.308474624502", "sample_id": "366062"}, "902227": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise91763/", "fauxness": "0.939597565642", "sample_id": "902227"}, "378888": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification77519/doover", "fauxness": "0.290081696741", "sample_id": "378888"}, "695618": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay34367doover", "fauxness": "0.590640556216", "sample_id": "695618"}, "735398": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification 19444/", "fauxness": "0.250289724637", "sample_id": "735398"}, "643787": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis_59866", "fauxness": "0.54939920547", "sample_id": "643787"}, "111525": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test.84424.2", "fauxness": "0.481879981176", "sample_id": "111525"}, "887469": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dry run13573.doover", "fauxness": "0.555031423058", "sample_id": "887469"}, "524952": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification 92167retry", "fauxness": "0.996125326195", "sample_id": "524952"}, "628280": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification76928_doover", "fauxness": "0.15717488126", "sample_id": "628280"}, "724070": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation.42872/2", "fauxness": "0.593640841146", "sample_id": "724070"}, "410800": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection/9922.", "fauxness": "0.967144566991", "sample_id": "410800"}, "93083": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test/73956", "fauxness": "0.923994924435", "sample_id": "93083"}, "434017": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial83293.", "fauxness": "0.883571469797", "sample_id": "434017"}, "499744": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run.208152", "fauxness": "0.203137344508", "sample_id": "499744"}, "860408": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run/62039 ", "fauxness": "0.946369760524", "sample_id": "860408"}, "492976": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure91306.retry", "fauxness": "0.142657448269", "sample_id": "492976"}, "332438": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection 764322", "fauxness": "0.00760762752965", "sample_id": "332438"}, "993829": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination66710", "fauxness": "0.493823069182", "sample_id": "993829"}, "846899": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise6236doover", "fauxness": "0.392027005034", "sample_id": "846899"}, "455555": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation_22755retry", "fauxness": "0.0251274953774", "sample_id": "455555"}, "798501": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay.57130.2", "fauxness": "0.223246877895", "sample_id": "798501"}, "158568": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial20822", "fauxness": "0.594137390394", "sample_id": "158568"}, "879250": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification32787.retry", "fauxness": "0.22355339749", "sample_id": "879250"}, "981443": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial/69237 ", "fauxness": "0.419641029616", "sample_id": "981443"}, "943880": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test 54852_", "fauxness": "0.850553547816", "sample_id": "943880"}, "604911": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis_61682 doover", "fauxness": "0.626812738397", "sample_id": "604911"}, "190042": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test.42442doover", "fauxness": "0.344410917067", "sample_id": "190042"}, "313303": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis60121.", "fauxness": "0.699100180622", "sample_id": "313303"}, "881576": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise3177.2", "fauxness": "0.347653490776", "sample_id": "881576"}, "81288": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation/28354", "fauxness": "0.19422523871", "sample_id": "81288"}, "883162": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run5320doover", "fauxness": "0.852868123024", "sample_id": "883162"}, "176731": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination75376/", "fauxness": "0.709493370907", "sample_id": "176731"}, "587834": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination2865.retry", "fauxness": "0.318451259599", "sample_id": "587834"}, "765111": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation75405doover", "fauxness": "0.546848500393", "sample_id": "765111"}, "533156": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice.40481", "fauxness": "0.403892531768", "sample_id": "533156"}, "256297": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study22819/", "fauxness": "0.363936736853", "sample_id": "256297"}, "371449": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice 67920", "fauxness": "0.35226052027", "sample_id": "371449"}, "639379": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt1101_", "fauxness": "0.1120572466", "sample_id": "639379"}, "548155": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "0.954028558959", "fauxness": "measure48", "sample_id": "548155"}, "14341": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial run1426doover", "fauxness": "0.557059050785", "sample_id": "14341"}, "47704": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure468 retry", "fauxness": "0.848300109175", "sample_id": "47704"}, "422951": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study_23420_", "fauxness": "0.830672796807", "sample_id": "422951"}, "204533": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run.20667_", "fauxness": "0.783341675524", "sample_id": "204533"}, "85204": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification 67302/2", "fauxness": "0.460382317415", "sample_id": "85204"}, "360804": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation6437", "fauxness": "0.302496171484", "sample_id": "360804"}, "121827": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection16655/", "fauxness": "0.244896087933", "sample_id": "121827"}, "574190": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise.424152", "fauxness": "0.280110511588", "sample_id": "574190"}, "673481": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study40616/", "fauxness": "0.138795211544", "sample_id": "673481"}, "269529": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run.18702 ", "fauxness": "0.762148904235", "sample_id": "269529"}, "105179": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification63213/retry", "fauxness": "0.125671148683", "sample_id": "105179"}, "35176": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run33247.", "fauxness": "0.0906044223443", "sample_id": "35176"}, "746098": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation 15280/doover", "fauxness": "0.394959534354", "sample_id": "746098"}, "463551": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise 21025_retry", "fauxness": "0.475427629867", "sample_id": "463551"}, "544676": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation26366.", "fauxness": "0.823794385821", "sample_id": "544676"}, "836242": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study17362doover", "fauxness": "0.458884687838", "sample_id": "836242"}, "557024": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study.37674_retry", "fauxness": "0.803828161031", "sample_id": "557024"}, "790265": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination83589/doover", "fauxness": "0.546524571819", "sample_id": "790265"}, "944767": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof.17915", "fauxness": "0.656973182231", "sample_id": "944767"}, "674236": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test.95231retry", "fauxness": "0.372442637332", "sample_id": "674236"}, "904299": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run.60506_retry", "fauxness": "0.851570477189", "sample_id": "904299"}, "320963": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run47654", "fauxness": "0.749786397967", "sample_id": "320963"}, "587843": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation 342712", "fauxness": "0.187629067481", "sample_id": "587843"}, "845901": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection/44926retry", "fauxness": "0.635449755903", "sample_id": "845901"}, "346253": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof12331doover", "fauxness": "0.700793044134", "sample_id": "346253"}, "82252": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure/80969/retry", "fauxness": "0.926991933808", "sample_id": "82252"}, "452985": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection.50642/", "fauxness": "0.583974947112", "sample_id": "452985"}, "539556": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof_99762", "fauxness": "0.352495971712", "sample_id": "539556"}, "391904": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis3583", "fauxness": "0.580059991669", "sample_id": "391904"}, "758947": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "exercise 910342", "fauxness": "0.452792079", "sample_id": "758947"}, "285615": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation_4612", "fauxness": "0.717912405893", "sample_id": "285615"}, "415496": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay3821retry", "fauxness": "0.737680769281", "sample_id": "415496"}, "938961": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection99019 ", "fauxness": "0.0654994533784", "sample_id": "938961"}, "492335": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection/86597.2", "fauxness": "0.585245344055", "sample_id": "492335"}, "511951": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "operation_44573.", "fauxness": "0.578344334515", "sample_id": "511951"}, "693610": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure.52463.", "fauxness": "0.915693669432", "sample_id": "693610"}, "856458": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification 69869doover", "fauxness": "0.158555277805", "sample_id": "856458"}, "465693": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial 92437", "fauxness": "0.0805053058699", "sample_id": "465693"}, "141085": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt.6769_2", "fauxness": "0.721773810017", "sample_id": "141085"}, "977166": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "measure17231_2", "fauxness": "0.821945797511", "sample_id": "977166"}, "639697": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise65666retry", "fauxness": "0.0191214030409", "sample_id": "639697"}, "23847": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise19006", "fauxness": "0.16203355078", "sample_id": "23847"}, "855418": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test624/", "fauxness": "0.999711972565", "sample_id": "855418"}, "427863": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification13148/retry", "fauxness": "0.965274210165", "sample_id": "427863"}, "877044": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study12771doover", "fauxness": "0.959712679861", "sample_id": "877044"}, "694582": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice/3485", "fauxness": "0.179462222477", "sample_id": "694582"}, "228313": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof.37559", "fauxness": "0.959841900766", "sample_id": "228313"}, "993462": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study/28355 doover", "fauxness": "0.796212371289", "sample_id": "993462"}, "182700": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial run_19265retry", "fauxness": "0.645569401852", "sample_id": "182700"}, "769270": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "operation.29133doover", "fauxness": "0.0572851863782", "sample_id": "769270"}, "94311": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dissection46139.doover", "fauxness": "0.50645331507", "sample_id": "94311"}, "790117": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection.33243", "fauxness": "0.749446545398", "sample_id": "790117"}, "64032": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "operation57564.", "fauxness": "0.483096734228", "sample_id": "64032"}, "652681": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "test_84867doover", "fauxness": "0.218874514991", "sample_id": "652681"}, "803345": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis_63348.", "fauxness": "0.840672187273", "sample_id": "803345"}, "624738": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification_76952", "fauxness": "0.432810910517", "sample_id": "624738"}, "143733": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial39628.", "fauxness": "0.23492782044", "sample_id": "143733"}, "358796": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof/97540_", "fauxness": "0.406301365328", "sample_id": "358796"}, "210234": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation48134 ", "fauxness": "0.407851603184", "sample_id": "210234"}, "480740": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test31721_doover", "fauxness": "0.60051290929", "sample_id": "480740"}, "690314": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial run 98297/", "fauxness": "0.0963089471554", "sample_id": "690314"}, "687641": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "analysis72091", "fauxness": "0.685768657468", "sample_id": "687641"}, "835533": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "assay_39245.2", "fauxness": "0.548370267187", "sample_id": "835533"}, "642344": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial run_80246/doover", "fauxness": "0.441888901366", "sample_id": "642344"}, "279372": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "test20221_", "fauxness": "0.72990139683", "sample_id": "279372"}, "888172": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "observation51012_2", "fauxness": "0.529691128997", "sample_id": "888172"}, "508603": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "analysis59174_", "fauxness": "0.455902019772", "sample_id": "508603"}, "749254": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination69369", "fauxness": "0.260108932008", "sample_id": "749254"}, "6626": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "proof73258/2", "fauxness": "0.821019956953", "sample_id": "6626"}, "923656": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial463802", "fauxness": "0.983224228005", "sample_id": "923656"}, "112884": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay_94657", "fauxness": "0.674894617586", "sample_id": "112884"}, "2342": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "assay/22889retry", "fauxness": "0.623378390177", "sample_id": "2342"}, "247263": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study44531_", "fauxness": "0.048809475138", "sample_id": "247263"}, "780718": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dry run36836_", "fauxness": "0.938024794572", "sample_id": "780718"}, "83110": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dissection2554_retry", "fauxness": "0.129234955447", "sample_id": "83110"}, "14234": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "exercise 2733/", "fauxness": "0.16296238817", "sample_id": "14234"}, "148975": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice 58547_retry", "fauxness": "0.171138831786", "sample_id": "148975"}, "432792": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "verification/34839/doover", "fauxness": "0.511585717942", "sample_id": "432792"}, "464678": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis.32335_", "fauxness": "0.297906724099", "sample_id": "464678"}, "825212": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification44807/doover", "fauxness": "0.31131489178", "sample_id": "825212"}, "626134": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice42314", "fauxness": "0.356126017359", "sample_id": "626134"}, "902284": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification.90770doover", "fauxness": "0.067807283971", "sample_id": "902284"}, "137550": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation50385", "fauxness": "0.735676723987", "sample_id": "137550"}, "890613": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof19727_", "fauxness": "0.532374515886", "sample_id": "890613"}, "302339": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification30045", "fauxness": "0.987376836104", "sample_id": "302339"}, "629675": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis/98517.", "fauxness": "0.315212356298", "sample_id": "629675"}, "770019": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination_33352_2", "fauxness": "0.960925119477", "sample_id": "770019"}, "911617": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study_62541/", "fauxness": "0.136362834488", "sample_id": "911617"}, "979054": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "trial.85014/doover", "fauxness": "0.501368983964", "sample_id": "979054"}, "106278": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "examination 51268 ", "fauxness": "0.450158154627", "sample_id": "106278"}, "202645": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "exercise/218822", "fauxness": "0.77210218128", "sample_id": "202645"}, "607200": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation 47011 ", "fauxness": "0.0618656656585", "sample_id": "607200"}, "550634": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study73341.", "fauxness": "0.451151992552", "sample_id": "550634"}, "403770": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay29030_retry", "fauxness": "0.0596399043792", "sample_id": "403770"}, "460440": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof.21802", "fauxness": "0.552960422289", "sample_id": "460440"}, "264570": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial78404/2", "fauxness": "0.717809973005", "sample_id": "264570"}, "138886": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination_58809 ", "fauxness": "0.257313904911", "sample_id": "138886"}, "758477": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt60019 doover", "fauxness": "0.840905878192", "sample_id": "758477"}, "649291": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "study_37557", "fauxness": "0.439437598648", "sample_id": "649291"}, "599271": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "measure3100.retry", "fauxness": "0.275004137717", "sample_id": "599271"}, "677768": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "practice 43720retry", "fauxness": "0.139904889948", "sample_id": "677768"}, "446014": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "observation 27526", "fauxness": "0.354487030884", "sample_id": "446014"}, "680137": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt67299", "fauxness": "0.859345416708", "sample_id": "680137"}, "316411": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test/26851retry", "fauxness": "0.449434332403", "sample_id": "316411"}, "572277": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "analysis92639_2", "fauxness": "0.391498744412", "sample_id": "572277"}, "866259": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "proof_10078 doover", "fauxness": "0.39489610155", "sample_id": "866259"}, "602325": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study 67464retry", "fauxness": "0.851837884663", "sample_id": "602325"}, "104896": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run60049/retry", "fauxness": "0.249435162333", "sample_id": "104896"}, "837251": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "trial98490retry", "fauxness": "0.887607765536", "sample_id": "837251"}, "91635": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "test_46272/", "fauxness": "0.455426707919", "sample_id": "91635"}, "998319": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "study80008", "fauxness": "0.254655524908", "sample_id": "998319"}, "543110": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "measure62354_", "fauxness": "0.43494064396", "sample_id": "543110"}, "458679": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "examination.54457.", "fauxness": "0.288705850172", "sample_id": "458679"}, "322877": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "verification/17347", "fauxness": "0.928445997885", "sample_id": "322877"}, "337160": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "study.55569 ", "fauxness": "0.806660896159", "sample_id": "337160"}, "226707": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "trial 26432.retry", "fauxness": "0.327912254104", "sample_id": "226707"}, "502389": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "observation19838 doover", "fauxness": "0.827342559873", "sample_id": "502389"}, "701615": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "dissection 13358.", "fauxness": "0.822063054868", "sample_id": "701615"}, "51610": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "dry run5605 ", "fauxness": "0.547967455186", "sample_id": "51610"}, "471385": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "attempt.63666.", "fauxness": "0.900901656981", "sample_id": "471385"}, "828156": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "verification94936_", "fauxness": "0.29497308872", "sample_id": "828156"}, "556522": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "practice83952_", "fauxness": "0.586184055102", "sample_id": "556522"}, "444460": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "attempt81975", "fauxness": "0.360820232284", "sample_id": "444460"}, "517331": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "assay1552.", "fauxness": "0.140736310705", "sample_id": "517331"}, "558971": {"filename": "file_7.faux", "active": true, "category_guess": "ambiguous", "experiment_name": "proof/272972", "fauxness": "0.565016191016", "sample_id": "558971"}, "240631": {"filename": "file_7.faux", "active": true, "category_guess": "real", "experiment_name": "dry run53413 ", "fauxness": "0.222073399885", "sample_id": "240631"}, "463043": {"filename": "file_7.faux", "active": true, "category_guess": "fake", "experiment_name": "examination64865retry", "fauxness": "0.938179068459", "sample_id": "463043"}}}
